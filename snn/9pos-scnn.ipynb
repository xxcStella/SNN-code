{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "# import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import sinabs\n",
    "import sinabs.activation\n",
    "import sinabs.layers as sl\n",
    "from sinabs.from_torch import from_model\n",
    "import os\n",
    "import shutil\n",
    "import samna\n",
    "from samna.unifirm.timestamp import StopWatch\n",
    "from sklearn.model_selection import KFold\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1, 16, 16])\n",
      "180 90\n"
     ]
    }
   ],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_path = os.listdir(self.root_dir)\n",
    "\n",
    "    # calculate the new matrix by suming every n columns\n",
    "    def sum_adjacent_cols(self, matrix, n):\n",
    "        num_cols = matrix.shape[1]\n",
    "        result = torch.zeros((matrix.shape[0],int(np.ceil(num_cols/n))))\n",
    "        for i in range(n):\n",
    "            result += matrix[:, i:num_cols:n]\n",
    "        return result\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, data_name)\n",
    "        with open(data_item_path, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "        data = torch.from_numpy(data).float()   # [256, 2000]\n",
    "        # data = torch.transpose(data, 0, 1)\n",
    "        data = self.sum_adjacent_cols(data, 10) # [256, 200]\n",
    "        data = torch.transpose(data, 0, 1)      # [200, 256]\n",
    "        data = data.view(200, 16, 16)           # [200, 16, 16]\n",
    "        data = data.unsqueeze(1)                # [200, 1, 16, 16]\n",
    "\n",
    "        if data_name[-6] == '_':\n",
    "            label = torch.tensor(eval(data_name[-5]), dtype=torch.long)\n",
    "        else:\n",
    "            label = torch.tensor(eval(data_name[-6:-4]), dtype=torch.long)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "root_dir_1 = '/home/xxc/PhD/synsense/Data/mg_tap_9positions/deep_learning/train'\n",
    "root_dir_2 = '/home/xxc/PhD/synsense/Data/mg_tap_9positions/deep_learning/test'\n",
    "\n",
    "train_data = MyData(root_dir_1)\n",
    "test_data  = MyData(root_dir_2)\n",
    "\n",
    "print(train_data[0][0].shape)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 20.83%, running_loss: 26.53, current_lr: 0.010000\n",
      "epoch: 1, accuracy: 47.50%, running_loss: 7.73, current_lr: 0.010000\n",
      "epoch: 2, accuracy: 60.00%, running_loss: 4.72, current_lr: 0.010000\n",
      "epoch: 3, accuracy: 66.67%, running_loss: 3.52, current_lr: 0.010000\n",
      "epoch: 4, accuracy: 90.83%, running_loss: 1.26, current_lr: 0.001000\n",
      "epoch: 5, accuracy: 92.50%, running_loss: 0.72, current_lr: 0.001000\n",
      "epoch: 6, accuracy: 92.50%, running_loss: 0.69, current_lr: 0.001000\n",
      "epoch: 7, accuracy: 92.50%, running_loss: 0.69, current_lr: 0.001000\n",
      "accuracy on validation set: 81.67%\n",
      "epoch: 0, accuracy: 20.83%, running_loss: 35.31, current_lr: 0.010000\n",
      "epoch: 1, accuracy: 24.17%, running_loss: 11.93, current_lr: 0.010000\n",
      "epoch: 2, accuracy: 34.17%, running_loss: 6.92, current_lr: 0.010000\n",
      "epoch: 3, accuracy: 63.33%, running_loss: 5.01, current_lr: 0.010000\n",
      "epoch: 4, accuracy: 67.50%, running_loss: 4.83, current_lr: 0.001000\n",
      "epoch: 5, accuracy: 65.00%, running_loss: 3.65, current_lr: 0.001000\n",
      "epoch: 6, accuracy: 72.50%, running_loss: 2.22, current_lr: 0.001000\n",
      "epoch: 7, accuracy: 93.33%, running_loss: 1.16, current_lr: 0.001000\n",
      "accuracy on validation set: 100.00%\n",
      "epoch: 0, accuracy: 18.33%, running_loss: 20.61, current_lr: 0.010000\n",
      "epoch: 1, accuracy: 15.00%, running_loss: 8.77, current_lr: 0.010000\n",
      "epoch: 2, accuracy: 30.00%, running_loss: 6.60, current_lr: 0.010000\n",
      "epoch: 3, accuracy: 79.17%, running_loss: 3.49, current_lr: 0.010000\n",
      "epoch: 4, accuracy: 86.67%, running_loss: 1.80, current_lr: 0.001000\n",
      "epoch: 5, accuracy: 91.67%, running_loss: 1.14, current_lr: 0.001000\n",
      "epoch: 6, accuracy: 91.67%, running_loss: 1.03, current_lr: 0.001000\n",
      "epoch: 7, accuracy: 95.83%, running_loss: 0.48, current_lr: 0.001000\n",
      "accuracy on validation set: 100.00%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "\n",
    "device = 'cuda:0'\n",
    "k_folds = 3\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "batch_size = 30\n",
    "time_steps = 200\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_val_acc = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data)):\n",
    "    # 模型初始化\n",
    "    linear_model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 3, 1, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2, 2),\n",
    "        nn.Conv2d(8, 16, 3, 1, bias=False),\n",
    "        nn.ReLU(),\n",
    "        # nn.AvgPool2d(2, 2),\n",
    "        nn.Conv2d(16, 32, 3, 1, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(288, 500, bias=False),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(500, 9, bias=False)\n",
    "    )\n",
    "    linear_model = from_model(linear_model, batch_size=batch_size, input_shape=(1, 16, 16), \n",
    "                        add_spiking_output=True, synops=False, num_timesteps=time_steps).to(device)\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "    # 分割数据集\n",
    "    train_sub = Subset(train_data, train_ids)\n",
    "    val_sub = Subset(train_data, val_ids)\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_sub, batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader  = DataLoader(val_sub, batch_size, drop_last=True)\n",
    "\n",
    "    # 训练模型\n",
    "    linear_model.train()\n",
    "    epochs = 8\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.\n",
    "        acc = 0\n",
    "        scheduler.step()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            linear_model.reset_states()\n",
    "\n",
    "            input = input.to(device)\n",
    "            input = input.view(batch_size*time_steps, 1, 16, 16)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(input)\n",
    "            output = output.view(batch_size, time_steps, 9)\n",
    "            sum_output = output.sum(1)\n",
    "            loss = loss_fn(sum_output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                if sum_output[j].argmax() == target[j]:\n",
    "                    acc += 1\n",
    "\n",
    "        print(\"epoch: %d, accuracy: %.2f%%, running_loss: %.2f, current_lr: %.6f\" \n",
    "              % (e, acc/len(train_sub)*100, running_loss, scheduler.get_last_lr()[0]) )\n",
    "    fold_train_acc.append(np.around(acc/len(train_sub)*100, 2))\n",
    "\n",
    "    # 验证模型\n",
    "    acc_num = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            linear_model.reset_states()\n",
    "            data = data.to(device)\n",
    "            data = data.view(batch_size*time_steps, 1, 16, 16)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(data)\n",
    "            output = output.view(batch_size, time_steps, 9)\n",
    "            sum_output = output.sum(1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if sum_output[j].argmax() == target[j]:\n",
    "                acc_num += 1\n",
    "    print(\"accuracy on validation set: %.2f%%\" % (acc_num/len(val_sub)*100))\n",
    "    fold_val_acc.append(np.around(acc_num/len(val_sub)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.5, 93.33, 95.83]\n",
      "[81.67, 100.0, 100.0]\n",
      "93.88666666666666\n",
      "93.89\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_acc)\n",
    "print(fold_val_acc)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_train_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_val_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/9pos-scnn.pth'\n",
    "torch.save(linear_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing set: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path)\n",
    "test_loader  = DataLoader(test_data, batch_size, drop_last=True)\n",
    "\n",
    "acc_num = 0\n",
    "model.eval()\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.reset_states()\n",
    "        data = data.to(device)\n",
    "        data = data.view(batch_size*time_steps, 1, 16, 16)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.view(batch_size, time_steps, 9)\n",
    "        sum_output = output.sum(1)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        if sum_output[j].argmax() == target[j]:\n",
    "            acc_num += 1\n",
    "print(\"accuracy on testing set: %.2f%%\" % (acc_num/len(test_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dobot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
